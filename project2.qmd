---
title: "Projeto: Previsão de Rotatividade de Clientes Bancários"
---

# Introdução

<p>
O problema de **churn**, ou rotatividade de clientes, representa um desafio significativo para instituições bancárias. Refere-se à taxa na qual os clientes encerram seus relacionamentos com o banco, migrando para outras instituições financeiras ou até mesmo abandonando serviços financeiros. Este fenômeno pode ser impulsionado por diversos fatores, como insatisfação com serviços, concorrência acirrada, mudanças nas condições econômicas e até mesmo avanços tecnológicos.
</p>

<p>
Dessa forma, a retenção de clientes torna-se uma prioridade estratégica para os bancos, que buscam constantemente inovar, oferecer experiências mais atrativas e personalizadas, a fim de mitigar o churn e manter uma base sólida de clientes leais.
</p>

<p>
Diante desse cenário, torna-se de extrema valia a capacidade de identificar os clientes mais propensos ao churn, possibilitando que a instituição financeira aja de maneira antecipada, oferecendo planos e serviços atrativos que impeçam a fuga do cliente.
</p>

# Problema de Negócio
Temos uma base de dados do ABC Multistate Bank, a qual está hospedada em <https://www.kaggle.com/datasets/gauravtopre/bank-customer-churn-dataset/data>. Essa base de dados contém informações anonimizadas de 10.000 clientes, onde o problema de negócio em questão resume-se a construirmos um modelo capaz de predizer a ocorrência ou não de churn para um dado cliente, com base nas informações disponíveis.


# Resolução do Problema

```{python}
#| echo: false
#| output: false
#| warning: false

#%% Setup
import itertools
import numpy as np
import pandas as pd

from scipy.stats             import shapiro, ks_2samp
from sklearn.model_selection import train_test_split
from sklearn.linear_model    import LogisticRegression
from sklearn.svm             import SVC, LinearSVC
from sklearn.neighbors       import KNeighborsClassifier
from sklearn.tree            import DecisionTreeClassifier
from sklearn.ensemble        import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing   import OneHotEncoder
import warnings

from functions import (
    create_table_categorical,
    create_graph_categorical,
    create_table_numeric_continuous,
    create_graph_numeric_continuous,
    bivariate,
    create_table_bivariate_summary,
    create_table_bivariate_html,
    create_graph_bivariate_html,
    create_graph_h_bivariate_html,
    binning_to_model,
    create_ks_table_for_logistic_regression,
    calculate_CramersV,
    calculate_CramersV2,
    show_df,
    create_confusion_matrix,
    show_confusion_matrix
    )

warnings.filterwarnings("ignore")
pd.set_option('display.max_columns', None) 
```

## Análise Exploratória dos Dados (EDA)
<p>O objetivo desta etapa é investigar e entender os dados disponíveis, a fim de extrair informações preliminares, identificar padrões, tendências, anomalias e insights relevantes.
</p>

<p>
Verificaremos que, ao término dessa análise, todas as variáveis apresentam comportamento adequado para prosseguirem no estudo, pois:

- Não possuem valores faltantes.
- Não têm valores inesperados.
- Não exibem alta concentração em um único valor.
</p>
<hr>

```{python}
#| echo: false
#| output: false

# Read files
file_name = "Bank Customer Churn Prediction"
df = pd.read_csv(f"./source/project2/{file_name}.csv")


# -> there is no duplciated customer
df.duplicated("customer_id").sum()

# -> there is no missing values
df.isna().sum()

# -> remove cols not useful
df.drop("customer_id", axis = 1, inplace = True)

# -> preprocessing
df_base = df.copy()

# "products_number"
df["products_number"] = np.where(df["products_number"] >= 4 , ">=4", df["products_number"].astype(int).astype(str))

# tenure
var_name = 'tenure'
c1 = df[var_name].between(0,  2,      inclusive = "both")
c2 = df[var_name].between(2,  4,      inclusive = "right")
c3 = df[var_name].between(4,  6,      inclusive = "right")
c4 = df[var_name].between(6,  8,      inclusive = "right")
c5 = df[var_name].between(8,  10,     inclusive = "right")
c6 = df[var_name].between(10, np.inf, inclusive = "neither")

df[var_name] = np.where(
    c1, '[0, 2]', np.where(
        c2, '(2, 4]', np.where(
            c3, '(4, 6]', np.where(
                c4, '(6, 8]', np.where(
                    c5, '(8, 10]', '>10' 
                    )
                )
            )
        )
    ) 
```

### Churn
Essa variável denota a ocorrência ou não do evento de churn.

- Não ocorrência de churn = 0
- Ocorrência de churn = 1


**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável target (binária).</li>
  <li>Temos 20% de ocorrência do evento.</li>
  <li>Temos 80% de não ocorrência do evento.</li>
</ul>

```{python}
#| fig-align: center
create_table_categorical("churn", df)
```

```{python}
#| fig-align: center
create_graph_categorical("churn", df)
```

<hr>

### Country
País do cliente.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável categórica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>França representa 50%.</li>
  <li>Alemanha e Espanha representam 25% cada.</li>
</ul>

```{python}
#| fig-align: center
create_table_categorical("country", df)
```

```{python}
#| fig-align: center
create_graph_categorical("country", df)
```

<hr>

### Gender
Gênero do cliente.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável categórica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>55% Homens.</li>
  <li>45% Mulheres.</li>
</ul>

```{python}
#| fig-align: center
create_table_categorical("gender", df)
```
```{python}
#| fig-align: center
create_graph_categorical("gender", df)
```

<hr>

### Credit Card
Se o cliente utiliza cartão de crédito.

- Não utiliza cartão de crédito = 0
- Utiliza cartão de crédito = 1

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável categórica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>71% utiliza cartão de cŕedito.</li>
  <li>29% não utiliza.</li>
</ul>

```{python}
#| fig-align: center
create_table_categorical("credit_card", df)
```
```{python}
#| fig-align: center
create_graph_categorical("credit_card", df)
```

<hr>

### Active Member
Denota se um cliente está envolvido e participando ativamente das atividades e serviços oferecidos pelo banco.

- Não ativo = 0
- Ativo = 1


**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável categórica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>Praticamente metade dos clientes são ativos e a outra metade é inativo.</li>
</ul>

```{python}
#| fig-align: center
create_table_categorical("active_member", df)
```
```{python}
#| fig-align: center
create_graph_categorical("active_member", df)
```

<hr>

### Products Number
Número de produtos adiquiridos pelo cliente.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável numérica discreta, mas será visualizada como categórica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>~50% dos cliente utilizam somente um produto.</li>
  <li>~46% dos cliente utilizam 2 produtos.</li>
</ul>

```{python}
#| fig-align: center
create_table_categorical("products_number", df, ['1', '2', '3', '>=4'])
```
```{python}
#| fig-align: center
create_graph_categorical("products_number", df, ['1', '2', '3', '>=4'])
```

<hr>

### Tenure
Mensura a quantidade de anos decorridos desde que o cliente aderiu aos serviços prestados pelo banco.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável numérica discreta, mas será visualizada como categórica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>25% de 0 a 2 anos.</li>
  <li>15% de 8 a 10 anos.</li>
  <li>As demais classes estão bem distribuídos em torno de 20%.</li>
</ul>

```{python}
#| fig-align: center
#fazer a mesma ordenção de baixo aqui
create_table_categorical("tenure", df, ['[0, 2]', '(2, 4]', '(4, 6]', '(6, 8]', '(8, 10]'])
```
```{python}
#| fig-align: center
create_graph_categorical("tenure", df, ['[0, 2]', '(2, 4]', '(4, 6]', '(6, 8]', '(8, 10]'])
```

<hr>

### Credit Score
É uma medida da probabilidade de um indivíduo pagar suas dívidas com base em seu histórico de crédito passado.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável numérica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>Possui distribuição aproximadamente normal, com média = 650.</li>
</ul>

```{python}
#| fig-align: center
create_table_numeric_continuous("credit_score", df)
```
```{python}
#| fig-align: center
create_graph_numeric_continuous("credit_score", df)
```

<hr>

### Age
Idade em anos do cliente.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável numérica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>Possui distribuição assimétrica á direita.</li>
  <li>Cliente mais novo tem 18 anos.</li>
  <li>Cliente mais velho tem 92 anos.</li>
  <li>O valor mediano da idade do cliente é de 37 anos.</li>

</ul>

```{python}
#| fig-align: center
create_table_numeric_continuous("age", df)
```
```{python}
#| fig-align: center
create_graph_numeric_continuous("age", df)
```

<hr>

### Balance
Saldo bancário do cliente

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável numérica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>Variável com distribuição assimétrica.</li>
  <li>Alta concetração de clientes com saldo entre 0 e 25 mil.</li>
</ul>

```{python}
#| fig-align: center
create_table_numeric_continuous("balance", df)
```
```{python}
#| fig-align: center
create_graph_numeric_continuous("balance", df)
```

<hr>

### Estimated Salary
Salario estimado.

**Avaliação**: <span style="color: green;"> OK. </span>
<ul>
  <li>Variável numérica.</li>
  <li>Não possui nenhum valor faltante.</li>
  <li>Variável com distribuição uniforme.</li>
</ul>

```{python}
#| fig-align: center
create_table_numeric_continuous("estimated_salary", df)
```
```{python}
#| fig-align: center
create_graph_numeric_continuous("estimated_salary", df)
```

## Análise Bivariada dos Dados
<p>
A análise bivariada tem como objetivo examinar a relação entre duas variáveis em um conjunto de dados. Ao contrário da análise univariada, que se concentra em uma única variável (EDA que fizemos no item anterior), a análise bivariada explora a associação entre duas variáveis.
</p>
 
<p>
Existem diferentes técnicas e métodos para realizar uma análise bivariada, dependendo da natureza das variáveis envolvidas.
Para o nosso problema, estamos interessados em avaliar o grau de associação entre cada uma das possíveis variáveis preditoras e a variável target, dessa forma temos que:

- churn: Categórica Binária (target)

- country: Categórica
- gender: Categórica
- credit_card: Categórica
- active_member: Categórica

- producs_number: Numérica Discreta
- tenure: Numérica Discreta
- credit_score: Numérica Contínua
- age: Numérica Discreta 

- balance: Numérica Contínua
- estimated_salary: Numérica Contínua
</p>

<p>
A nossa abordagem será transformar todas as variáveis preditoras em categóricas, para posteriormente avaliarmos o grau de associação de cada uma delas frente a variável target, para isso teremos basicamente duas etapas:
<ol>
  <li>Binning das variáveis.</li>
  <li>Avaliação do Grau de Associação.</li>
</ol>
</p>

<hr>

**Binning**
<p>
Chamaremos esse processo de transformação de uma variável numérica em categórica de binning. O processo de binning será feito através de um método denominado de  **optimal binning** <https://gnpalencia.org/optbinning/>.
</p>

<p>
O optimal binning refere-se a uma abordagem estatística utilizada em análise de dados para agrupar valores de uma variável em intervalos (ou "bins") de maneira a otimizar algum critério específico. A principal ideia por trás do binning ótimo é encontrar a divisão mais informativa ou significativa das observações, geralmente com base em algum critério de interesse, como a maximização da diferença nas médias entre os grupos ou a minimização da variabilidade intra-bin.
</p>

<p>
Ou seja, de forma resumida, vamos pegar um certa variável, por exemplo o balance (saldo da conta) e tentar discretizar em categorias onde fique mais evidente se a ocorrência de churn é maior ou menor.
</p>

<p>
Vale ressaltar que também vamos aplicar o optimal binning para as variáveis que já são categóricas, uma vez que esse processo de otimização pode gerar agrupamentos mais informativos (quanto a ocorrência de churn) do que as categorias já existentes.
</p>

<hr>

**Avaliação do Grau de Associação**
<p>
Neste momento todas as nossas variáveis (preditoras e target) são categóricas, então para mensurar o grau de associação entre cada preditora e o target, utilizaremos o coeficiente **Cramer's V** (V de Cramer).
</p>

<p>
O coeficiente V de Cramer é uma medida estatística utilizada em análises bivariadas para quantificar a força de associação entre duas variáveis categóricas. Essa medida é uma extensão do coeficiente qui-quadrado, que é comumente utilizado para testar a independência entre variáveis categóricas.

O coeficiente V de Cramer varia de 0 a 1, onde 0 indica nenhuma associação e 1 indica associação total entre as variáveis categóricas.
<https://en.wikipedia.org/wiki/Cram%C3%A9r%27s_V>
</p>

<hr>

**Resultado da Análise Bivariada**

Após o término da análise bivariada, conforme a tabela abaixo e os demais resultados que veremos na sequência, veremos que:

- age: É a variável com maior grau de associação com o evento de churn (Alta discriminância).
- products_number, country, active_member: Estão associadas de forma moderada com o evento de churn (Média discriminância).
- credit_score, tenure, estimated_salary e credit_card: Possuem baixo grau de associação com o evento de churn (Baixa discriminância).

As variáveis com alta e média discriminância têm maiores chances de serem consideradas como preditoras no modelo preditivo que iremos construir. Em contrapartida, as variáveis de baixa discriminância possuem menor propensão de serem utilizadas como preditoras nesse modelo."


**Observação** 
<p>
O critério utilizado para definir a discriminância não está levando em conta apenas se o valor de Cramer’s V está muito próximo de 0 ou 1, mas também considera o contexto dessa análise. Por exemplo, para a variável idade, temos Cramer’s V = 0.36, que é um valor mais próximo de 0 do que de 1. Se considerássemos apenas essa questão, diríamos que o grau de associação é moderado ou baixo.

No entanto, no contexto desta análise, a variável idade é a que possui o maior Cramer’s V. Portanto, dentro do nosso contexto, estamos considerando que o grau de associação com o evento é forte.

Para fins de esclarecimento, consideramos que:

- Cramer's V > 0.20: Discriminância Alta.
- 0.20 <= Cramer's V < 0.05: Discriminância Média.
- Cramer's V <= 0.05: Discriminância Baixa.
</p>

```{python}
#| fig-align: center
numerical_variables = [
    "products_number",
    "tenure",
    "credit_score",
    "age",
    "estimated_salary"
    ]

categorical_variables = [
    "country", 
    "gender", 
    "credit_card",
    "active_member",
    "balance",
    ]

target_variable = 'churn'

df = df_base

# balance
var_name = 'balance'
c1 = df[var_name].between(-np.inf,  1884.34, inclusive = "neither")
df[var_name] = np.where(c1, '< 1884.34', '>= 1884.34')

df_bivariate = bivariate(
    df,
    numerical_variables,
    categorical_variables,
    target_variable)

df_bivariate.rename(columns = {"Indicador":"Feature"}, inplace = True)

df = (
  df_bivariate[["Feature", "Cramer's V", "Discriminância"]]
  .drop_duplicates()
  .sort_values(by = ["Cramer's V", "Feature"], ascending = False)
  .reset_index(drop = True)
  )
    
create_table_bivariate_summary(df, cols_float = ["Cramer's V"])
```

### Age

**Discriminância**: <span style="color: green;"> Alta. </span>
<ul>
  <li>Quanto mais velho for o cliente, maior é a propensão de ocorrência do churn.</li>
</ul>

```{python}
#| fig-align: center
var = "age"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Products Number

**Discriminância**: <span style="color: yellow;"> Média. </span>
<ul>
  <li>A ocorrência do churn é maior para clientes que contrataram somente 1 produto.</li>
</ul>

```{python}
#| fig-align: center
var = "products_number"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Country

**Discriminância**: <span style="color: yellow;"> Média. </span>
<ul>
  <li>A ocorrência do churn é maior para clientes da Alemanha.</li>
</ul>

```{python}
#| fig-align: center
var = "country"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Active Member

**Discriminância**: <span style="color: yellow;"> Média. </span>
<ul>
  <li>A ocorrência do churn é maior para clientes que não são ativos.</li>
</ul>

```{python}
#| fig-align: center
var = "active_member"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Balance

**Discriminância**: <span style="color: yellow;"> Média. </span>
<ul>
  <li>A ocorrência do churn é maior para clientes com saldo em conta maior ou igual a 1884.34 .</li>
</ul>

```{python}
#| fig-align: center
var = "balance"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Gender

**Discriminância**: <span style="color: yellow;"> Média. </span>
<ul>
  <li>A ocorrência do churn é maior para clientes do sexo feminino.</li>
</ul>

```{python}
#| fig-align: center
var = "gender"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Credit Score

**Discriminância**: <span style="color: #800000;"> Baixa. </span>
<ul>
  <li>O fato isolado de quão bom ou ruim é o credit_score do cliente, não tem forte relação com o evento de churn.</li>
</ul>

```{python}
#| fig-align: center
var = "credit_score"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Tenure

**Discriminância**: <span style="color: #800000;"> Baixa. </span>
<ul>
  <li>O fato isolado da quantidade de anos decorridos desde que o cliente aderiu aos serviços prestados pelo banco, não tem forte relação com o evento de churn.</li>
</ul>

```{python}
#| fig-align: center
var = "tenure"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Estimated Salary

**Discriminância**: <span style="color: #800000;"> Baixa. </span>
<ul>
  <li>O fato isolado de quão alto ou baixo é o salário do cliente, não tem forte relação com o evento de churn.</li>
</ul>

```{python}
#| fig-align: center
var = "estimated_salary"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

<hr>

### Credit Card

**Discriminância**: <span style="color: #800000;"> Baixa. </span>
<ul>
  <li>O fato isolado do cliente ter ou não cartão de cŕedito, não tem forte relação com o evento de churn.</li>
</ul>

```{python}
#| fig-align: center
var = "credit_card"
create_table_bivariate_html(df_bivariate, var)
```

```{python}
#| fig-align: center
create_graph_bivariate_html(df_bivariate, var)
```

## O Modelo Preditivo
**Em desenvolvimento - Não está pronto ainda**

**Técnica Utilizada**

<p>
Quanto à modelagem, um ponto deve ser enfatizado: o principal objetivo aqui é a construção de um modelo preditivo que possua um grau de interpretabilidade relativamente fácil para a área de negócios. Portanto, nosso foco é obter não apenas um modelo assertivo, mas sim um modelo com bom desempenho e de fácil entendimento. Dito isso, vamos modelar utilizando a técnica de **Regressão Logística**.
</p>

<p>
A regressão logística é uma técnica estatística utilizada para modelar a relação entre uma variável dependente binária (que possui apenas dois valores possíveis, geralmente 0 e 1) e uma ou mais variáveis independentes. Ela é amplamente empregada em problemas de classificação, onde o objetivo é prever a probabilidade de uma observação pertencer a uma determinada categoria.
</p>

<p>
A principal característica da regressão logística é sua capacidade de lidar com problemas de classificação binária, como por exemplo, prever se um e-mail é spam ou não, se um paciente tem uma determinada condição médica ou não, entre outros cenários onde a resposta desejada é dicotômica.
</p>

<p>
A forma básica da regressão logística é expressa pela seguinte equação:

![](./img/regressao_logistica.png){fig-align="center" }

Contextualizando a formula acima para o nosso problema, temos que:

- X1, X2, ... Xn são as nossas features: country, gender, credit_card, active_member, producs_number, tenure, credit_score, age, balance, estimated_salary.
- A probabilide p do evento Y = 1, é a probabilidade de ocorrência de churn.
- Os betas B0, B1, ... Bn representam os parâmetros do modelo, que pretendemos obter ao construir o modelo matemático.
</p>

<hr>

**Avaliação do Modelo**

<p>
O teste de Kolmogorov-Smirnov (KS) pode ser utilizado como uma métrica para avaliar a qualidade de modelos de classificação, especialmente em problemas de classificação binária. Nesse contexto, o KS é frequentemente empregado para avaliar a capacidade do modelo em distinguir entre as classes positiva e negativa.
</p>

<p>
A abordagem mais comum envolve a geração de pontuações (scores) ou probabilidades de predição para as instâncias de ambas as classes pelo modelo. Em seguida, o teste de Kolmogorov-Smirnov é aplicado às distribuições cumulativas dessas pontuações para as duas classes. O objetivo é verificar se há uma diferença significativa entre as distribuições cumulativas das classes positiva e negativa.
</p>

<p>
Quanto maior for a diferença entre as distribuições cumulativas, maior será o valor de KS e, consequentemente, mais eficiente será o modelo, ou seja, mais capaz de classificar corretamente o que é churn e o que não é churn.
</p>

<hr>

**Obtendo o melhor modelo**

<p>
A partir das 10 variáveis preditoras disponíveis, foram testadas todas as combinações possíveis, selecionando de 5 a 10 variáveis por vez. Dessa forma, examinamos 638 modelos de regressão logística, avaliando o valor de KS para cada modelo nos dados de teste. Optamos pelo modelo que apresentou o maior valor de KS e o menor número de variáveis preditoras que parecem ser mais relevantes para o negócio.
</p>

<p>
Portanto, o modelo selecionado foi o que apresentou KS = 0.36 e possui as seguintes variáveis preditoras:

- 'products_number'
- 'country'
- 'gender'
- 'credit_card'
- 'active_member'

</p>

```{python}
#| echo: false
#| output: false


# Read files
file_name   = "Bank Customer Churn Prediction"
df_original = pd.read_csv(f"./source/project2/{file_name}.csv")
df          = df_original.copy()

numerical_variables = [
    "products_number",
    "tenure",
    "credit_score",
    "age",
    "estimated_salary"
    ]

categorical_variables = [
    "country", 
    "gender", 
    "credit_card",
    "active_member",
    "balance",
    ]

target_variable = 'churn'

"""
lst = numerical_variables + categorical_variables 

cols_combine = []
for i in range(5, len(lst) + 1):
    cols_combine += list(itertools.combinations(lst, i)) 

# Models
seed   = 100
df     = df[numerical_variables + categorical_variables + [target_variable]]
X_all  = df.drop(target_variable, axis=1).copy()
y      = df[target_variable].copy()
j      = 1
df_res = pd.DataFrame()

for m in cols_combine:
     
    print(j)
    j += 1
    
    # Select features
    X = X_all[list(m)]
    original_cols = X.columns

    # Split
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)
    
    # ----------------------------------- Binnings --------------------------------
    df_train = pd.merge(X_train,
                        y_train, 
                        how         = "left", 
                        left_index  = True, 
                        right_index = True,
                        validate    = "one_to_one")
    
    df_test = pd.merge(X_test,
                       y_test, 
                       how         = "left", 
                       left_index  = True, 
                       right_index = True,
                       validate    = "one_to_one")
                
    
    df_train = binning_to_model(
        df_train,
        list(df_train.columns[df_train.columns.isin(numerical_variables)]),
        list(df_train.columns[df_train.columns.isin(categorical_variables)]),
        target_variable).reset_index(drop = True)
    
    df_test = binning_to_model(
        df_test,
        list(df_test.columns[df_test.columns.isin(numerical_variables)]),
        list(df_test.columns[df_test.columns.isin(categorical_variables)]),
        target_variable).reset_index(drop = True)
    
    X_train  = df_train.drop(target_variable, axis=1).copy()
    y_train  = df_train[target_variable].copy()
    
    X_test  = df_test.drop(target_variable, axis=1).copy()
    y_test  = df_test[target_variable].copy()
     
    # -----------------------------------------------------------------------------
    
    # One-hot Encoding
    enc = OneHotEncoder(handle_unknown='ignore', drop = 'first')
    enc.fit(X_train.astype(str))
    
    colnames = enc.get_feature_names_out()
    
    # train
    transformed = enc.transform(X_train.astype(str)).toarray()
    df_cat_vars = pd.DataFrame(columns=colnames, data=transformed)
    X_train = pd.concat([X_train, df_cat_vars], axis=1)
    
    # test
    transformed = enc.transform(X_test.astype(str)).toarray()
    df_cat_vars = pd.DataFrame(columns=colnames, data=transformed)
    X_test = pd.concat([X_test, df_cat_vars], axis=1)
    
    # Remocao das variáveis categoricas sem codificação
    X_train.drop(original_cols, axis=1, inplace = True)
    X_test.drop(original_cols, axis=1, inplace = True)
    
    # Models
    models = []
    models.append(("LogisticRegression",LogisticRegression()))

    for name,model in models:
        result = cross_val_score(model, X_train, y_train,  cv=5)
        
        clf = LogisticRegression()
        clf.fit(X_train, y_train)

        nos_train = create_ks_table_for_logistic_regression(clf, X_train, y_train)
        nos_test  = create_ks_table_for_logistic_regression(clf, X_test, y_test)
        
        
        df_aux = pd.DataFrame()
        df_aux["name"] = [name]
        df_aux["mean accuracy "] = [result.mean()]
        df_aux["std accuracy"]   = [result.std()]
        df_aux["predictors"]     = [m]
        df_aux["KS_train"]       = nos_train["KS"].unique()
        df_aux["KS_test"]        = nos_test["KS"].unique()
        
        df_res = pd.concat([df_res, df_aux])
    
df_res.reset_index(drop = True, inplace = True)
df_res.to_pickle("best_models.pkl")
"""
#df_res = pd.read_pickle("best_models.pkl")

```


<p>
Representação gráfica do cálculo do KS nos dados de teste para o modelo selecionado.
</p>

```{python}
#| fig-align: center

seed          = 100
X             = df[['products_number', 'country', 'gender', 'credit_card', 'active_member']].copy()
y             = df[target_variable].copy()
original_cols = X.columns

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=seed)

# ----------------------------------- Binnings --------------------------------
df_train = pd.merge(X_train,
                    y_train, 
                    how         = "left", 
                    left_index  = True, 
                    right_index = True,
                    validate    = "one_to_one")

df_test = pd.merge(X_test,
                   y_test, 
                   how         = "left", 
                   left_index  = True, 
                   right_index = True,
                   validate    = "one_to_one")
            

df_train = binning_to_model(
    df_train,
    list(df_train.columns[df_train.columns.isin(numerical_variables)]),
    list(df_train.columns[df_train.columns.isin(categorical_variables)]),
    target_variable).reset_index(drop = True)

df_test = binning_to_model(
    df_test,
    list(df_test.columns[df_test.columns.isin(numerical_variables)]),
    list(df_test.columns[df_test.columns.isin(categorical_variables)]),
    target_variable).reset_index(drop = True)

X_train  = df_train.drop(target_variable, axis=1).copy()
y_train  = df_train[target_variable].copy()

X_test  = df_test.drop(target_variable, axis=1).copy()
y_test  = df_test[target_variable].copy()
 
# -----------------------------------------------------------------------------

# One-hot Encoding
enc = OneHotEncoder(handle_unknown='ignore', drop = 'first')
enc.fit(X_train.astype(str))

colnames = enc.get_feature_names_out()

# train
transformed = enc.transform(X_train.astype(str)).toarray()
df_cat_vars = pd.DataFrame(columns=colnames, data=transformed)
X_train = pd.concat([X_train, df_cat_vars], axis=1)

# test
transformed = enc.transform(X_test.astype(str)).toarray()
df_cat_vars = pd.DataFrame(columns=colnames, data=transformed)
X_test = pd.concat([X_test, df_cat_vars], axis=1)

# Remocao das variáveis categoricas sem codificação
X_train.drop(original_cols, axis=1, inplace = True)
X_test.drop(original_cols, axis=1, inplace = True)

# Treino
clf = LogisticRegression()
clf.fit(X_train, y_train)

#nos_train = create_ks_table_for_logistic_regression(clf, X_train, y_train)
nos_test  = create_ks_table_for_logistic_regression(clf, X_test, y_test)


y_pred = np.round(clf.predict_proba(X_test)[:, 1], 2)
y_pred = np.where(y_pred >= 0.19, 1, 0)
 
y_test = np.where(y_test == 1, "Churn", "Não-Churn")
y_pred = np.where(y_pred == 1, "Churn", "Não-Churn")
```


**Faixas de operação do modelo selecionado**

<p>
A tabela abaixo apresenta todas as possíveis faixas de operação do modelo selecionado a qual foi aplicada na base de testes. Do ponto de vista técnico, a faixa 8 em destaque é considerada a faixa ótima, pois possui **Sens. + Espec. - 1 = KS = 0**. Isso significa que essa é a faixa com maior capacidade de classificação correta do que é **Churn** e **Não-Churn**.
</p>

<p>
Interpretando a tabela para essa faixa, temos que:

**Prob = 19%**: Significa que, se a probabilidade de ocorrência do churn for maior ou igual a 19%, o modelo classificará como churn.

**% Total acumulado = 40%**: Significa que, dos clientes que o algoritmo avaliar, ele classificará 40% como churn.

**Tx. classificados como 1 corretamente = 35%**: Significa que, dos clientes que o algoritmo classificar como churn, 35% realmente realizariam churn, enquanto os outros 65% não realizariam.

**Tx. classificados como 0 corretamente = 89%**: Significa que, dos clientes que o algoritmo classificar como Não-Churn, 89% realmente não realizariam churn, enquanto os outros 11% realizariam.

**Sens. = 68%**: É a sensibilidade. Significa que, de todos os casos de churn, o modelo será capaz de classificar corretamente 68% deles, enquanto os outros 32% serão classificados como Não-Churn.

**Espec. = 67%**: É a especificidade. Significa que, de todos os casos de Não-churn, o modelo será capaz de classificar corretamente 67% deles, enquanto os outros 33% serão classificados como Churn.

**Sens. + Espec. - 1 = 0.36**: Utilizado para calcular o valor aproximado de KS e comparar com o KS obtido no gráfico acima.

**Acurácia**: De todos os clientes avaliados pelo algoritmo, o percentual de acertos, incluindo churn e não churn, é de 67%.
</p>

```{python}
#| fig-align: center
#| 
nos_test.drop(["Evento acumulado", "Nao-evento acumulado", "Ganho 1's","Ganho 0's"], axis = 1, inplace = True)

COLOR           = "#001820"
df              = nos_test
cols_to_percent = [
  "Prob",
  "% Total acumulado",
  "Tx. classificados como 1 corretamente",
  "Tx. classificados como 0 corretamente", 
  "Sens.", 
  "Espec.",
  "Acurácia", 
  ]

cols_to_float = ["Sens. + Espec. - 1"]

df_styled = (
    df.style
        # Cor do header e index
        .set_table_styles([{
            'selector': 'th:not(.index_name)',
            'props': f'background-color: {COLOR}; color: white; text-align: center;'
        }]) 
        .set_properties(
          **{'text-align': "center"})
        .set_properties(
            subset = ([7],) ,
            **{'background-color': "#C5D9F1",
                'color'          : "black",
                'font-weight'    : "bold",
                'text-align'     : "center"
              })
        .format('{:.0%}', subset= cols_to_percent) 
        .format('{:.2f}', subset= cols_to_float) 
        .hide(axis="index")
    )
df_styled
```

**Conclusões Sobre o Modelo**

Mas afinal, esse modelo é bom ou ruim? Para responder a essa pergunta, devemos comparar duas situações: quando o modelo é utilizado e quando não é.

***Sem o modelo:***

- Sem o modelo, não temos nenhuma outra forma de identificar quais clientes estariam mais propensos ao churn e tentar alguma abordagem para resgatar a confiança deles, evitando sua fuga.

- Isso ocorrendo, o banco teria uma redução de cerca de 20% de seus clientes.

***Com o modelo:***

- 68% dos casos possíveis de churn seriam identificados previamente, enquanto os demais 32% não seriam identificados.

- Supondo que um plano de ação seja capaz de impedir o churn de todos os possíveis churn identificados (os 68%), o banco teria uma redução em sua carteira de clientes de apenas 6,4% (32% dos churns, os quais não foram identificados pelo modelo).

- Obviamente, os erros do modelo em classificar Não-churn como churn também geram custos para o banco, pois ele gastará dinheiro para resgatar um cliente que, de fato, não corria risco de perda. Isso ocorrerá em 65% dos casos em que o modelo classificar como churn. De fato, 40% de todos os clientes serão classificados como churn pelo modelo, sendo que apenas 35% desse público realizaria o churn. A questão é que o modelo adota uma postura muito conservadora, onde a perda do cliente é considerada algo muito mais severo do que o gasto com programas para evitar o churn. Por isso, se a probabilidade de ocorrência do churn for maior ou superior a 19%, o modelo prefere recomendar uma ação do banco para tentar evitar a fuga desse cliente.

- Diante do exposto anteriormente, podemos afirmar que o modelo tem uma boa performance. No entanto, a decisão final de utilizá-lo ou não viria após uma análise de ganho financeiro, comparando o seu uso com a não utilização.